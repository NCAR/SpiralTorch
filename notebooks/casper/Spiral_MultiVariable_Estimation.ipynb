{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb0d448-e379-4ef7-8aa3-4443c0186790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d6fcd-c852-4efe-9353-5935b8014ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458517a-c940-4faf-97c5-00412cbce1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file path information from the home directory\n",
    "file_path_yml = os.path.join(os.environ[\"HOME\"], \".ncar_config_derecho.yaml\")\n",
    "path_data = {}\n",
    "with open(file_path_yml, \"r\") as r:\n",
    "    path_data = yaml.safe_load(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c01d85-4a4d-4f1e-afc3-a8bbdb7a5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirP_str = os.path.join(\n",
    "    path_data[\"ptv_collection_path\"], \"SpiralTorch\", \"python\"\n",
    ")\n",
    "if dirP_str not in sys.path:\n",
    "    sys.path.append(dirP_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24556ec-7b8e-4679-8060-c2e295bf9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpiralTorch import spiral\n",
    "from SpiralTorch import loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3895d6-0912-4e49-a892-0e22147a25ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this block to autodetect if a GPU is available\n",
    "is_cuda = torch.cuda.is_available()\n",
    "device = torch.device(torch.cuda.current_device()) if is_cuda else torch.device(\"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "if is_cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(f'Preparing to use device {device}')\n",
    "\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e519f-d4d2-4627-bacf-be1684fc13ae",
   "metadata": {},
   "source": [
    "# Simulate Poisson Observations\n",
    "Generate a scene of data similar to depolarization where one channel observes a parallel and perpendicular polarization term such that the mean photon flux in each channel is\n",
    "\n",
    "$\\alpha_1 = \\beta(1-d/2)$\n",
    "\n",
    "$\\alpha_2 = \\frac{1}{2}\\beta d$\n",
    "\n",
    "and the observations are \n",
    "\n",
    "$y_1 \\sim Poisson(\\alpha_1)$\n",
    "\n",
    "$y_2 \\sim Poisson(\\alpha_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33013ae1-dc3d-4031-aedd-4ad9b422109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.linspace(-10,10,64)\n",
    "y_axis = np.linspace(-10,10,128)\n",
    "x_ax_mesh,y_ax_mesh = np.meshgrid(x_axis,y_axis)\n",
    "\n",
    "rec_count = 80\n",
    "ch_count = 2\n",
    "\n",
    "# uniform distribution\n",
    "# rec_x_position_arr = 20*(np.random.rand(rec_count)-0.5)\n",
    "# rec_y_position_arr = 20*(np.random.rand(rec_count)-0.5)\n",
    "# normal distribution\n",
    "rec_x_position_arr = 5*(np.random.randn(rec_count))\n",
    "rec_y_position_arr = 5*(np.random.randn(rec_count))\n",
    "rec_x_arr = np.random.randn(rec_count)*5\n",
    "rec_y_arr = np.random.randn(rec_count)*5\n",
    "beta_rec_arr = 20*np.random.rand(rec_count)\n",
    "d_rec_arr = np.random.rand(rec_count)\n",
    "\n",
    "beta_bg = 4\n",
    "d_bg = 0.1\n",
    "\n",
    "alpha_arr_lst = []\n",
    "for idx in range(ch_count):\n",
    "    if idx == 0:\n",
    "        alpha_arr_lst.append(np.zeros((y_axis.size,x_axis.size))+0.5*beta_bg*(1-d_bg))\n",
    "    elif idx == 1:\n",
    "        alpha_arr_lst.append(np.zeros((y_axis.size,x_axis.size))+0.5*beta_bg*d_bg)\n",
    "\n",
    "for idx in range(rec_count):\n",
    "    rec_idx = np.where((y_ax_mesh >= rec_y_position_arr[idx]-rec_y_arr[idx]/2) & (y_ax_mesh <= rec_y_position_arr[idx]+rec_y_arr[idx]/2) & \\\n",
    "             (x_ax_mesh >= rec_x_position_arr[idx]-rec_x_arr[idx]/2) & (x_ax_mesh <= rec_x_position_arr[idx]+rec_x_arr[idx]/2))\n",
    "    \n",
    "    alpha_arr_lst[0][rec_idx]+=beta_rec_arr[idx]*(1-0.5*d_rec_arr[idx])\n",
    "    alpha_arr_lst[1][rec_idx]+=0.5*beta_rec_arr[idx]*d_rec_arr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec1259-0304-4091-956c-d6cd7414abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_act = {\n",
    "    'beta':alpha_arr_lst[0]+alpha_arr_lst[1],\n",
    "    'd':2*alpha_arr_lst[1]/(alpha_arr_lst[1]+alpha_arr_lst[0])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466b6ac-2a43-42f7-8a83-df76037da699",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_obs_fit_lst = []\n",
    "y_obs_val_lst = []\n",
    "# create fit and validation data for the scene\n",
    "for ch_idx, alpha_arr in enumerate(alpha_arr_lst):\n",
    "    y_obs_fit_lst.append(np.random.poisson(alpha_arr))\n",
    "    y_obs_val_lst.append(np.random.poisson(alpha_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f130b2-f977-4932-8eca-88825e0b5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,len(alpha_arr_lst),figsize=(10,5))\n",
    "for ch_idx, alpha_arr in enumerate(alpha_arr_lst):\n",
    "    im = ax[ch_idx].imshow(alpha_arr)\n",
    "    ax[ch_idx].set_title(f\"True Ch {ch_idx}\")\n",
    "    if ch_idx == 0:\n",
    "        clim = im.get_clim()\n",
    "    else:\n",
    "        im.set_clim(clim)\n",
    "\n",
    "fig,ax = plt.subplots(1,len(alpha_arr_lst),figsize=(10,5))\n",
    "for ch_idx, y_arr in enumerate(y_obs_fit_lst):\n",
    "    im = ax[ch_idx].imshow(y_arr)\n",
    "    ax[ch_idx].set_title(f\"Observed Ch {ch_idx}\")\n",
    "    if ch_idx == 0:\n",
    "        clim = im.get_clim()\n",
    "    else:\n",
    "        im.set_clim(clim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b73821-0c20-4c6f-a628-1d551d77c6c7",
   "metadata": {},
   "source": [
    "# Process Scene using Spiral TV with regularizer optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8747abf-48db-46c1-a942-96e61aa45c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_ver_str = 'jit-fista'  # 'cuda-fista', 'jit-fista'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeabd44-0781-4dbc-9c75-cbf152f5fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_reg_dct = {\n",
    "    'd':np.logspace(0.8,1.5,5),\n",
    "    'beta':np.logspace(0,0.7,5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d974bcd-4f83-4752-92a7-837c7fd4305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create regularizer grid\n",
    "tv_lst = []\n",
    "for var in tv_reg_dct:\n",
    "    tv_lst.append(tv_reg_dct[var])\n",
    "\n",
    "tv_mesh_tup = np.meshgrid(*tv_lst)\n",
    "\n",
    "grid_count = tv_mesh_tup[0].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dba622-dbd0-4e12-a8cd-7a74a45ac58e",
   "metadata": {},
   "source": [
    "Define forward models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b310b81-3390-4727-b759-525b43595e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_pois_fwd_model(**x):\n",
    "    \"\"\"\n",
    "    forward model for parallel polarization channel\n",
    "    \n",
    "    expects x['beta'] - backscatter\n",
    "            x['d'] - depolarization\n",
    "    returns \n",
    "            fwd_mod['y_mean_est']\n",
    "    \"\"\"\n",
    "    fwd_mod = {\n",
    "        'y_mean_est':torch.exp(x['beta'])*(1-x['d']*0.5)\n",
    "    }\n",
    "    return fwd_mod\n",
    "\n",
    "def perp_pois_fwd_model(**x):\n",
    "    \"\"\"\n",
    "    forward model for perpendicular polarization channel\n",
    "    \n",
    "    expects x['beta'] - backscatter\n",
    "            x['d'] - depolarization\n",
    "    returns \n",
    "            fwd_mod['y_mean_est']\n",
    "    \"\"\"\n",
    "    fwd_mod = {\n",
    "        'y_mean_est':0.5*torch.exp(x['beta'])*x['d']\n",
    "    }\n",
    "    return fwd_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0760e0c2-d8af-486d-89bc-a79ea5a731f3",
   "metadata": {},
   "source": [
    "load the observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6d40c-ea7d-4e1f-95c0-89b9a06c36d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwd_model_lst = [\n",
    "    parallel_pois_fwd_model,\n",
    "    perp_pois_fwd_model,\n",
    "]\n",
    "\n",
    "y_fit_dct_lst = []\n",
    "y_val_dct_lst = []\n",
    "\n",
    "for idx, y_fit in enumerate(y_obs_fit_lst):\n",
    "    y_fit_dct_lst.append({'counts':y_fit})\n",
    "    y_val_dct_lst.append({'counts':y_obs_val_lst[idx]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a01ebc-56d3-480a-8efd-884e46ccdb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create spiral optimization object\n",
    "spiral_opt = spiral.multiSpiral_autograd(device,dtype)\n",
    "spiral_opt.set_fista_version(fista_ver_str)\n",
    "spiral_opt.set_fwd_model_lst(fwd_model_lst)\n",
    "spiral_opt.set_y_fit_lst(y_fit_dct_lst)\n",
    "spiral_opt.set_y_val_lst(y_val_dct_lst)\n",
    "spiral_opt.set_noise_model(['poisson','poisson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b6b95-b664-4190-96a4-d6bcfd82236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for alignment between observations and the noise model inputs\n",
    "pass_test_bool, out_text, = spiral_opt.check_noise_model_inputs()\n",
    "print(f\"check passed: {pass_test_bool}\")\n",
    "print(out_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa30032-8259-4dd1-8e50-a2b1b2b9cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsa_subprob_config_dct = {\n",
    "    'beta':{\n",
    "        'alpha_min':1e4,\n",
    "        'alpha_max':1e20,\n",
    "        'alpha':1,\n",
    "    },\n",
    "    'd':{\n",
    "        'alpha_min':1e4,\n",
    "        'alpha_max':1e20,\n",
    "        'alpha':1,\n",
    "    }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef03f1-784f-4ff7-b6a6-e3683e5f5b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the initial conditions\n",
    "x0 = {\n",
    "    'beta':np.zeros(y_obs_fit_lst[0].shape)+np.log(10),\n",
    "    'd':np.zeros(y_obs_fit_lst[0].shape)+0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f11287-13f0-42dc-9af7-c9717517a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the variables to be estimated (and order)\n",
    "spiral_opt.set_estimate_lst(['beta','d'])\n",
    "\n",
    "# this is where the subproblems for each variable get created, so there needs to be an entry for each\n",
    "spiral_opt.add_sparsa_config(sparsa_subprob_config_dct)\n",
    "spiral_opt.set_initial_conditions(x0)\n",
    "# spiral_opt.set_tv_penalties({'beta':1e0,'d':1e1})  # this must happen after the subproblem is defined\n",
    "spiral_opt.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820828d2-3272-4ad5-8193-e4115cb0f8f6",
   "metadata": {},
   "source": [
    "Run the spiral optimizer over the regularizer search space.  Store the Validation NLL for each outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fca73b7-8f27-468b-829e-a7c05b54e950",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sol_lst = []\n",
    "vld_loss_lst = []\n",
    "opt_time_lst = []\n",
    "for idx in range(grid_count):\n",
    "    tv_dct = {}\n",
    "    for var_idx, var in enumerate(tv_reg_dct):\n",
    "        tv_dct[var] = tv_mesh_tup[var_idx].flatten()[idx]\n",
    "        print(var+f\": {tv_mesh_tup[var_idx].flatten()[idx]}\")\n",
    "    spiral_opt.set_tv_penalties(tv_dct)  # this must happen after the subproblem is defined\n",
    "    \n",
    "    # reinitialize\n",
    "    # spiral_opt.set_alpha(1.0)\n",
    "    spiral_opt.set_initial_conditions(x0)\n",
    "    \n",
    "    # optimize\n",
    "    spiral_opt.solve()\n",
    "\n",
    "    # store result\n",
    "    x_sol = spiral_opt.get_x()\n",
    "    x_sol_lst.append(x_sol)\n",
    "    vld_loss = spiral_opt.valid_loss()  # this is used for TV regularization optimization\n",
    "    vld_loss_lst.append(vld_loss)\n",
    "    opt_time_lst.append(spiral_opt.stop_time - spiral_opt.start_time)\n",
    "    print(f\"validation loss: {vld_loss}\")\n",
    "    print(f\"optimization time: {opt_time_lst[-1]} seconds\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c58efa6-bcb7-45da-ae40-1556fe1240b0",
   "metadata": {},
   "source": [
    "Locate the best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f6c7f-fa19-4457-b4d9-c45f54ba1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_idx = np.argmin(vld_loss_lst)\n",
    "x_sol = x_sol_lst[sol_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7b99f-28b3-4197-85b1-ad363cf91db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the regularizer search space\n",
    "var_idx_x = 0\n",
    "var_idx_y = 1\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "tv_var_x = list(tv_reg_dct.keys())[var_idx_x]\n",
    "tv_var_y = list(tv_reg_dct.keys())[var_idx_y]\n",
    "\n",
    "im = ax.scatter(tv_mesh_tup[var_idx_x].flatten(),tv_mesh_tup[var_idx_y].flatten(),c=vld_loss_lst)\n",
    "ax.plot(tv_mesh_tup[var_idx_x].flatten()[sol_idx],tv_mesh_tup[var_idx_y].flatten()[sol_idx],'wx')\n",
    "ax.set_xlabel(tv_var_x + \" Regularizer\")\n",
    "ax.set_ylabel(tv_var_y + \" Regularizer\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(visible=True)\n",
    "plt.colorbar(im,ax=ax,label=\"validation NLL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d277d-bde6-4e1e-a8f7-a8f64892866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the solution and actual data for comparison\n",
    "plt_x_dct = {\n",
    "    'beta':{'function':np.exp,'label':r'$\\beta$'},\n",
    "    'd':{'label':r'$d$'}\n",
    "}\n",
    "clim_dct = {}\n",
    "\n",
    "fig,ax = plt.subplots(1,len(x_act.keys()),figsize=(10,5))\n",
    "for var_idx, var in enumerate(x_act_test):\n",
    "    im = ax[var_idx].imshow(x_act_test[var])\n",
    "    ax[var_idx].set_title(f\"Actual \"+plt_x_dct[var]['label'])\n",
    "    clim_dct[var] = im.get_clim()\n",
    "    plt.colorbar(im,ax=ax[var_idx])\n",
    "    \n",
    "\n",
    "fig,ax = plt.subplots(1,len(x_sol.keys()),figsize=(10,5))\n",
    "for var_idx, var in enumerate(x_sol):\n",
    "    if 'function' in plt_x_dct[var]:\n",
    "        plot_arr = plt_x_dct[var]['function'](x_sol[var])\n",
    "    else:\n",
    "        plot_arr = x_sol[var]\n",
    "    im = ax[var_idx].imshow(plot_arr)\n",
    "    ax[var_idx].set_title(f\"Estimated \"+plt_x_dct[var]['label'])\n",
    "    im.set_clim(clim_dct[var])\n",
    "    plt.colorbar(im,ax=ax[var_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f48e8-562f-4a49-b6fa-2e31969c5536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the forward model of the solution for each channel\n",
    "fwd_model_dct_lst = []\n",
    "\n",
    "x_sol_tnsr = {}\n",
    "\n",
    "for var in x_sol:\n",
    "    x_sol_tnsr[var] = spiral_opt.to_tensor(x_sol[var])\n",
    "\n",
    "for idx, model in enumerate(spiral_opt.fwd_model_lst):\n",
    "    y_est = model(**x_sol_tnsr)\n",
    "    fwd_dct = {}\n",
    "    for var in y_est:\n",
    "        fwd_dct[var] = y_est[var].detach().cpu()\n",
    "    fwd_model_dct_lst.append(fwd_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c5a79-03e3-4f4a-a0de-b2270b64b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a cross section of the forward model\n",
    "obs_var = 'counts'\n",
    "fwd_mod_var = 'y_mean_est'\n",
    "time_idx = 20\n",
    "\n",
    "for idx, fwd_mod in enumerate(fwd_model_dct_lst):\n",
    "    plt.figure()\n",
    "    plt.plot(y_fit_dct_lst[idx][obs_var][time_idx,:],label='observation')\n",
    "    plt.plot(alpha_arr_lst[idx][time_idx,:],label='actual')\n",
    "    plt.plot(fwd_mod[fwd_mod_var][time_idx,:],label='estimate')\n",
    "    plt.legend()\n",
    "    plt.title(f\"Channel {idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptv-casper-cuda]",
   "language": "python",
   "name": "conda-env-ptv-casper-cuda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
